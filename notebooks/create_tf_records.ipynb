{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Google - American Sign Language Fingerspelling Recognition with TensorFlow\n","\n","This notebook walks you through how to train a Transformer model using TensorFlow on the Google - American Sign Language Fingerspelling Recognition dataset made available for this competition.\n","\n","The objective of the model is to predict and translate American Sign Language (ASL) fingerspelling from a set of video frames into text(`phrase`).\n","\n","In this notebook you will learn:\n","\n","- How to load the data\n","- Convert the data to tfrecords to make it faster to re-traing the model\n","- Train a transformer models on the data\n","- Convert the model to TFLite\n","- Create a submission"]},{"cell_type":"markdown","metadata":{},"source":["# Installation\n","\n","Specifically for this competition, you'll need the mediapipe library to work on the data and visualize it"]},{"cell_type":"markdown","metadata":{},"source":["# Import the libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-08-21T23:32:38.547502Z","iopub.status.busy":"2023-08-21T23:32:38.546299Z","iopub.status.idle":"2023-08-21T23:32:47.532702Z","shell.execute_reply":"2023-08-21T23:32:47.531750Z","shell.execute_reply.started":"2023-08-21T23:32:38.547445Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-08-24 02:18:56.582945: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-08-24 02:18:57.255810: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["import os\n","import shutil\n","import numpy as np\n","import pandas as pd\n","import pyarrow.parquet as pq\n","import tensorflow as tf\n","import json\n","# import mediapipe\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import random\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tqdm.auto import tqdm"]},{"cell_type":"markdown","metadata":{},"source":["# Load the Dataset"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["sup_dataset_df = pd.read_csv(\"../data/asl-fingerspelling/supplemental_metadata.csv\")"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["52958"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["sup_dataset_df.shape[0]"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>path</th>\n","      <th>file_id</th>\n","      <th>sequence_id</th>\n","      <th>participant_id</th>\n","      <th>phrase</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>supplemental_landmarks/33432165.parquet</td>\n","      <td>33432165</td>\n","      <td>1535467051</td>\n","      <td>251</td>\n","      <td>coming up with killer sound bites</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>supplemental_landmarks/33432165.parquet</td>\n","      <td>33432165</td>\n","      <td>1535499058</td>\n","      <td>239</td>\n","      <td>we better investigate this</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>supplemental_landmarks/33432165.parquet</td>\n","      <td>33432165</td>\n","      <td>1535530550</td>\n","      <td>245</td>\n","      <td>interesting observation was made</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>supplemental_landmarks/33432165.parquet</td>\n","      <td>33432165</td>\n","      <td>1535545499</td>\n","      <td>38</td>\n","      <td>victims deserve more redress</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>supplemental_landmarks/33432165.parquet</td>\n","      <td>33432165</td>\n","      <td>1535585216</td>\n","      <td>254</td>\n","      <td>knee bone is connected to the thigh bone</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                      path   file_id  sequence_id  \\\n","0  supplemental_landmarks/33432165.parquet  33432165   1535467051   \n","1  supplemental_landmarks/33432165.parquet  33432165   1535499058   \n","2  supplemental_landmarks/33432165.parquet  33432165   1535530550   \n","3  supplemental_landmarks/33432165.parquet  33432165   1535545499   \n","4  supplemental_landmarks/33432165.parquet  33432165   1535585216   \n","\n","   participant_id                                    phrase  \n","0             251         coming up with killer sound bites  \n","1             239                we better investigate this  \n","2             245          interesting observation was made  \n","3              38              victims deserve more redress  \n","4             254  knee bone is connected to the thigh bone  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["sup_dataset_df.head()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["508"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# how much I could add?\n","\n","sup_dataset_df.drop_duplicates(subset=[\"phrase\"]).shape[0]"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-08-21T23:32:47.545836Z","iopub.status.busy":"2023-08-21T23:32:47.545495Z","iopub.status.idle":"2023-08-21T23:32:47.722253Z","shell.execute_reply":"2023-08-21T23:32:47.721271Z","shell.execute_reply.started":"2023-08-21T23:32:47.545802Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Full train dataset shape is (67208, 5)\n"]}],"source":["dataset_df = pd.read_csv(\"../data/asl-fingerspelling/train.csv\")\n","\n","print(\"Full train dataset shape is {}\".format(dataset_df.shape))"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["46478"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["dataset_df.drop_duplicates(subset=[\"phrase\"]).shape[0]"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-08-21T23:33:04.434561Z","iopub.status.busy":"2023-08-21T23:33:04.434238Z","iopub.status.idle":"2023-08-21T23:33:04.440200Z","shell.execute_reply":"2023-08-21T23:33:04.439353Z","shell.execute_reply.started":"2023-08-21T23:33:04.434531Z"},"trusted":true},"outputs":[],"source":["# Pose coordinates for hand movement.\n","LPOSE = [13, 15, 17, 19, 21]\n","RPOSE = [14, 16, 18, 20, 22]\n","POSE = LPOSE + RPOSE"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-08-21T23:33:04.442333Z","iopub.status.busy":"2023-08-21T23:33:04.441634Z","iopub.status.idle":"2023-08-21T23:33:04.453426Z","shell.execute_reply":"2023-08-21T23:33:04.452804Z","shell.execute_reply.started":"2023-08-21T23:33:04.442295Z"},"trusted":true},"outputs":[],"source":["X = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in POSE]\n","Y = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in POSE]\n","Z = [f'z_right_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in POSE]"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-08-21T23:33:04.455385Z","iopub.status.busy":"2023-08-21T23:33:04.454807Z","iopub.status.idle":"2023-08-21T23:33:04.464882Z","shell.execute_reply":"2023-08-21T23:33:04.464187Z","shell.execute_reply.started":"2023-08-21T23:33:04.455354Z"},"trusted":true},"outputs":[],"source":["FEATURE_COLUMNS = X + Y + Z"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-08-21T23:33:04.466503Z","iopub.status.busy":"2023-08-21T23:33:04.465963Z","iopub.status.idle":"2023-08-21T23:33:04.476973Z","shell.execute_reply":"2023-08-21T23:33:04.476280Z","shell.execute_reply.started":"2023-08-21T23:33:04.466476Z"},"trusted":true},"outputs":[],"source":["X_IDX = [i for i, col in enumerate(FEATURE_COLUMNS)  if \"x_\" in col]\n","Y_IDX = [i for i, col in enumerate(FEATURE_COLUMNS)  if \"y_\" in col]\n","Z_IDX = [i for i, col in enumerate(FEATURE_COLUMNS)  if \"z_\" in col]\n","\n","RHAND_IDX = [i for i, col in enumerate(FEATURE_COLUMNS)  if \"right\" in col]\n","LHAND_IDX = [i for i, col in enumerate(FEATURE_COLUMNS)  if  \"left\" in col]\n","RPOSE_IDX = [i for i, col in enumerate(FEATURE_COLUMNS)  if  \"pose\" in col and int(col[-2:]) in RPOSE]\n","LPOSE_IDX = [i for i, col in enumerate(FEATURE_COLUMNS)  if  \"pose\" in col and int(col[-2:]) in LPOSE]"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-08-21T23:33:04.478624Z","iopub.status.busy":"2023-08-21T23:33:04.478094Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f66fff4b37741ecbb6f7ea715dacd04","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/68 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Loop through each file_id\n","for file_id in tqdm(dataset_df.file_id.unique()):\n","    # Parquet file name\n","    pq_file = f\"../data/asl-fingerspelling/train_landmarks/{file_id}.parquet\"\n","    # Filter train.csv and fetch entries only for the relevant file_id\n","    file_df = dataset_df.loc[dataset_df[\"file_id\"] == file_id]\n","    # Fetch the parquet file\n","    parquet_df = pq.read_table(f\"../data/asl-fingerspelling/train_landmarks/{str(file_id)}.parquet\",\n","                              columns=['sequence_id'] + FEATURE_COLUMNS).to_pandas()\n","    # File name for the updated data\n","    tf_file = f\"../data/asl-fingerspelling/tfrecords/train_landmarks/{file_id}.tfrecord\"\n","    parquet_numpy = parquet_df.to_numpy()\n","    # Initialize the pointer to write the output of \n","    # each `for loop` below as a sequence into the file.\n","    with tf.io.TFRecordWriter(tf_file) as file_writer:\n","        # Loop through each sequence in file.\n","        for seq_id, phrase in zip(file_df.sequence_id, file_df.phrase):\n","            # Fetch sequence data\n","            frames = parquet_numpy[parquet_df.index == seq_id]\n","            \n","            # Calculate the number of NaN values in each hand landmark\n","            r_nonan = np.sum(np.sum(np.isnan(frames[:, RHAND_IDX]), axis = 1) == 0)\n","            l_nonan = np.sum(np.sum(np.isnan(frames[:, LHAND_IDX]), axis = 1) == 0)\n","            no_nan = max(r_nonan, l_nonan)\n","            \n","            if 2*len(phrase)<no_nan:\n","                features = {FEATURE_COLUMNS[i]: tf.train.Feature(\n","                    float_list=tf.train.FloatList(value=frames[:, i])) for i in range(len(FEATURE_COLUMNS))}\n","                features[\"phrase\"] = tf.train.Feature(bytes_list=tf.train.BytesList(value=[bytes(phrase, 'utf-8')]))\n","                record_bytes = tf.train.Example(features=tf.train.Features(feature=features)).SerializeToString()\n","                file_writer.write(record_bytes)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
