{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 16:33:48.135620: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-17 16:33:48.790168: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import tensorflow_models as tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"../data/asl-fingerspelling\"\n",
    "TRAIN_LANDMARKS_PATH = DATASET_DIR+os.sep+\"train_landmarks\"\n",
    "SUPPLEMENTAL_LANDMARKS_PATH = DATASET_DIR+os.sep+\"supplemental_landmarks\"\n",
    "TRAIN_PATH = DATASET_DIR+os.sep+\"train.csv\"\n",
    "TFRECORDS_PATH = DATASET_DIR+os.sep+\"tfrecords\"\n",
    "list_files = np.array([TFRECORDS_PATH+os.sep+\"train_landmarks\"+os.sep+file_name for file_name in os.listdir(TFRECORDS_PATH+os.sep+\"train_landmarks/\")])\n",
    "\n",
    "# save_tfrecords(train_df)\n",
    "# I'm only interested in the hand coordinates, x and y\n",
    "landmark_sequence = pd.read_parquet(DATASET_DIR+os.sep+\"train_landmarks/5414471.parquet\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_columns(df):\n",
    "    columns_right_hand = [column for column in df.columns if \"x_right_hand\" in column or \"y_right_hand\" in column]\n",
    "    columns_left_hand = [column for column in df.columns if \"x_left_hand\" in column or \"y_left_hand\" in column]\n",
    "    return columns_right_hand + columns_left_hand\n",
    "\n",
    "FEATURE_COLUMNS = get_columns(landmark_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train split: 28160 | val split: 6656\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "N = list_files.shape[0]*512\n",
    "\n",
    "train_split = math.ceil(N*0.8)\n",
    "validation_split = N - train_split\n",
    "\n",
    "number_of_train_files = math.ceil(train_split/512)\n",
    "\n",
    "np.random.shuffle(list_files)\n",
    "\n",
    "train_files = list_files[:number_of_train_files]\n",
    "val_files = list_files[number_of_train_files:]\n",
    "\n",
    "print(f\"train split: {train_files.shape[0]*512} | val split: {val_files.shape[0]*512}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['../data/asl-fingerspelling/tfrecords/train_landmarks/2072876091.tfrecord',\n",
       "       '../data/asl-fingerspelling/tfrecords/train_landmarks/450474571.tfrecord',\n",
       "       '../data/asl-fingerspelling/tfrecords/train_landmarks/1497621680.tfrecord',\n",
       "       '../data/asl-fingerspelling/tfrecords/train_landmarks/532011803.tfrecord',\n",
       "       '../data/asl-fingerspelling/tfrecords/train_landmarks/1969985709.tfrecord',\n",
       "       '../data/asl-fingerspelling/tfrecords/train_landmarks/296317215.tfrecord',\n",
       "       '../data/asl-fingerspelling/tfrecords/train_landmarks/1726141437.tfrecord',\n",
       "       '../data/asl-fingerspelling/tfrecords/train_landmarks/175396851.tfrecord',\n",
       "       '../data/asl-fingerspelling/tfrecords/train_landmarks/614661748.tfrecord',\n",
       "       '../data/asl-fingerspelling/tfrecords/train_landmarks/1358493307.tfrecord'],\n",
       "      dtype='<U72')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"../data/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n",
    "    char_to_num=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(char_to_num.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '!': 1,\n",
       " '#': 2,\n",
       " '$': 3,\n",
       " '%': 4,\n",
       " '&': 5,\n",
       " \"'\": 6,\n",
       " '(': 7,\n",
       " ')': 8,\n",
       " '*': 9,\n",
       " '+': 10,\n",
       " ',': 11,\n",
       " '-': 12,\n",
       " '.': 13,\n",
       " '/': 14,\n",
       " '0': 15,\n",
       " '1': 16,\n",
       " '2': 17,\n",
       " '3': 18,\n",
       " '4': 19,\n",
       " '5': 20,\n",
       " '6': 21,\n",
       " '7': 22,\n",
       " '8': 23,\n",
       " '9': 24,\n",
       " ':': 25,\n",
       " ';': 26,\n",
       " '=': 27,\n",
       " '?': 28,\n",
       " '@': 29,\n",
       " '[': 30,\n",
       " '_': 31,\n",
       " 'a': 32,\n",
       " 'b': 33,\n",
       " 'c': 34,\n",
       " 'd': 35,\n",
       " 'e': 36,\n",
       " 'f': 37,\n",
       " 'g': 38,\n",
       " 'h': 39,\n",
       " 'i': 40,\n",
       " 'j': 41,\n",
       " 'k': 42,\n",
       " 'l': 43,\n",
       " 'm': 44,\n",
       " 'n': 45,\n",
       " 'o': 46,\n",
       " 'p': 47,\n",
       " 'q': 48,\n",
       " 'r': 49,\n",
       " 's': 50,\n",
       " 't': 51,\n",
       " 'u': 52,\n",
       " 'v': 53,\n",
       " 'w': 54,\n",
       " 'x': 55,\n",
       " 'y': 56,\n",
       " 'z': 57,\n",
       " '~': 58}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([w for w, _ in char_to_num.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add pad_token, start pointer and end pointer to the dict\n",
    "start_token = \"<\"\n",
    "end_token = \">\"\n",
    "pad_token = \"P\"\n",
    "space_token = \" \"\n",
    "unk_token = \"[UNK]\"\n",
    "pad_token_idx = 0\n",
    "space_token_idx = 59\n",
    "unk_token_idx = -1\n",
    "start_token_idx = 60\n",
    "end_token_idx = 61\n",
    "\n",
    "char_to_num[pad_token] = pad_token_idx\n",
    "char_to_num[space_token] = space_token_idx\n",
    "char_to_num[unk_token] = unk_token_idx\n",
    "char_to_num[start_token] = start_token_idx\n",
    "char_to_num[end_token] = end_token_idx\n",
    "num_to_char = {j:i for i,j in char_to_num.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 16:33:52.131859: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-17 16:33:52.150177: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-17 16:33:52.150333: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-17 16:33:52.151190: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-17 16:33:52.151322: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-17 16:33:52.151441: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-17 16:33:52.652579: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-17 16:33:52.652748: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-17 16:33:52.652872: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-17 16:33:52.652964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 508 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "TARGET_MAX_LENGHT = 32\n",
    "\n",
    "def decode_fn(record_bytes):\n",
    "    schema = {COL: tf.io.VarLenFeature(dtype=tf.float32) for COL in FEATURE_COLUMNS}\n",
    "    schema[\"phrase\"] = tf.io.FixedLenFeature([], dtype=tf.string)\n",
    "    features = tf.io.parse_single_example(record_bytes, schema)\n",
    "    phrase = features[\"phrase\"]\n",
    "    landmarks = ([tf.sparse.to_dense(features[COL]) for COL in FEATURE_COLUMNS])\n",
    "    # Transpose to maintain the original shape of landmarks data.\n",
    "    landmarks = tf.transpose(landmarks)\n",
    "    \n",
    "    return landmarks, phrase\n",
    "\n",
    "table = tf.lookup.StaticHashTable(\n",
    "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=list(char_to_num.keys()),\n",
    "        values=list(char_to_num.values()),\n",
    "    ),\n",
    "    default_value=tf.constant(-1),\n",
    "    name=\"class_weight\"\n",
    ")\n",
    "\n",
    "itext_vectorizer = tf.keras.layers.TextVectorization(\n",
    "    output_sequence_length=TARGET_MAX_LENGHT,\n",
    "    output_mode=\"int\",\n",
    "    standardize=None,\n",
    "    split=\"character\",\n",
    "    vocabulary=[w for w, _ in char_to_num.items()]\n",
    ")\n",
    "\n",
    "def convert_fn(landmarks, phrase):\n",
    "    # Add start and end pointers to phrase.\n",
    "    phrase_with_start_end_token = start_token + phrase + end_token\n",
    "    print(phrase_with_start_end_token)\n",
    "    phrase_splited = tf.strings.bytes_split(phrase_with_start_end_token)\n",
    "    print(phrase_splited)\n",
    "    phrase_with_indexes = table.lookup(phrase_splited)\n",
    "    print(phrase_with_indexes)\n",
    "    # Vectorize and add padding.\n",
    "    # 65 added the UNK token\n",
    "    phrase_vectorized = tf.pad(\n",
    "                                phrase_with_indexes,\n",
    "                                # paddings=[[0, len([w for w, _ in num_to_char.items()])-tf.shape(phrase_with_indexes)[0]]],\n",
    "                                paddings=[[0, 32]],\n",
    "                                mode = 'CONSTANT',\n",
    "                                constant_values = pad_token_idx\n",
    "                        )\n",
    "    return landmarks, phrase_vectorized\n",
    "\n",
    "def vectorizer_preprocess(landmarks, phrase):\n",
    "    return landmarks, itext_vectorizer(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_num[\">\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<3 crecks>\n",
      "tf.Tensor([b'<' b'3' b' ' b'c' b'r' b'e' b'c' b'k' b's' b'>'], shape=(10,), dtype=string)\n",
      "tf.Tensor([60 18 59 34 49 36 34 42 50 61], shape=(10,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "result = convert_fn([], \"3 crecks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([],\n",
       " <tf.Tensor: shape=(42,), dtype=int32, numpy=\n",
       " array([60, 18, 59, 34, 49, 36, 34, 42, 50, 61,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0], dtype=int32)>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_1:0\", shape=(), dtype=string)\n",
      "Tensor(\"StringsByteSplit/RaggedGetItem/strided_slice_5:0\", shape=(None,), dtype=string)\n",
      "Tensor(\"None_Lookup/LookupTableFindV2:0\", shape=(None,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "train_dataset_raw_labels = tf.data.TFRecordDataset(train_files).map(decode_fn).padded_batch(64)\n",
    "train_dataset = tf.data.TFRecordDataset(train_files).map(decode_fn).map(convert_fn).padded_batch(64)\n",
    "train_dataset_textvectorizer = tf.data.TFRecordDataset(train_files).map(decode_fn).map(vectorizer_preprocess).padded_batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45, 34, 14, 35, 34, 51, 51, 34, 16, 36, 34, 51, 48, 40, 48, 15, 49,\n",
       "       41, 49,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset_textvectorizer))[1][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([60, 43, 32, 12, 33, 32, 49, 49, 32, 14, 34, 32, 49, 46, 38, 46, 13,\n",
       "       47, 39, 47, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))[1][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nc/dcttc1ectqiq0rjrPPPPPPPPPPPPP'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join([num_to_char[index] for index in next(iter(train_dataset_textvectorizer))[1][0].numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<la-barra/carogo.php>PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join([num_to_char[index] for index in next(iter(train_dataset))[1][0].numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'la-barra/carogo.php'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset_raw_labels))[1][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{59: ' ',\n",
       " 1: '!',\n",
       " 2: '#',\n",
       " 3: '$',\n",
       " 4: '%',\n",
       " 5: '&',\n",
       " 6: \"'\",\n",
       " 7: '(',\n",
       " 8: ')',\n",
       " 9: '*',\n",
       " 10: '+',\n",
       " 11: ',',\n",
       " 12: '-',\n",
       " 13: '.',\n",
       " 14: '/',\n",
       " 15: '0',\n",
       " 16: '1',\n",
       " 17: '2',\n",
       " 18: '3',\n",
       " 19: '4',\n",
       " 20: '5',\n",
       " 21: '6',\n",
       " 22: '7',\n",
       " 23: '8',\n",
       " 24: '9',\n",
       " 25: ':',\n",
       " 26: ';',\n",
       " 27: '=',\n",
       " 28: '?',\n",
       " 29: '@',\n",
       " 30: '[',\n",
       " 31: '_',\n",
       " 32: 'a',\n",
       " 33: 'b',\n",
       " 34: 'c',\n",
       " 35: 'd',\n",
       " 36: 'e',\n",
       " 37: 'f',\n",
       " 38: 'g',\n",
       " 39: 'h',\n",
       " 40: 'i',\n",
       " 41: 'j',\n",
       " 42: 'k',\n",
       " 43: 'l',\n",
       " 44: 'm',\n",
       " 45: 'n',\n",
       " 46: 'o',\n",
       " 47: 'p',\n",
       " 48: 'q',\n",
       " 49: 'r',\n",
       " 50: 's',\n",
       " 51: 't',\n",
       " 52: 'u',\n",
       " 53: 'v',\n",
       " 54: 'w',\n",
       " 55: 'x',\n",
       " 56: 'y',\n",
       " 57: 'z',\n",
       " 58: '~',\n",
       " 0: 'P',\n",
       " -1: '[UNK]',\n",
       " 60: '<',\n",
       " 61: '>'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 294, 84), dtype=float32, numpy=\n",
       " array([[[0.28413114, 0.36007503, 0.44180965, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.26482275, 0.3005719 , 0.36837673, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.23754913, 0.31357628, 0.39528942, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       " \n",
       "        [[0.40615228, 0.4608809 , 0.47783646, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.39446467, 0.44435763, 0.4467729 , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.38341478, 0.4231695 , 0.41584805, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       " \n",
       "        [[0.45956957, 0.5176132 , 0.6134128 , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.45791274, 0.47697645, 0.54094166, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.47088045, 0.45970118, 0.49932247, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.        , 0.        , 0.        , ..., 0.62686765,\n",
       "          0.59761953, 0.5691456 ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.5440475 ,\n",
       "          0.5174508 , 0.50224125],\n",
       "         [0.        , 0.        , 0.        , ..., 0.53172886,\n",
       "          0.5486182 , 0.575901  ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       " \n",
       "        [[0.21360156, 0.28442773, 0.36425868, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.22588864, 0.3029908 , 0.3888847 , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.17276967, 0.25210768, 0.31355727, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       " \n",
       "        [[0.19244066, 0.29221362, 0.37056905, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.08653039, 0.19435698, 0.2942649 , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.13343604, 0.22839971, 0.30940497, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 32), dtype=int64, numpy=\n",
       " array([[45, 34, 14, ...,  0,  0,  0],\n",
       "        [24, 25, 20, ...,  0,  0,  0],\n",
       "        [18, 19, 25, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [46, 48, 45, ...,  0,  0,  0],\n",
       "        [12, 19, 24, ...,  0,  0,  0],\n",
       "        [26, 17, 23, ...,  0,  0,  0]])>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset_textvectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 294, 84), dtype=bool, numpy=\n",
       "array([[[ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[False, False, False, ...,  True,  True,  True],\n",
       "        [False, False, False, ...,  True,  True,  True],\n",
       "        [False, False, False, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]]])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.not_equal(next(iter(train_dataset_textvectorizer))[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Transformers.Decoder import TransformerDecoder\n",
    "from Transformers.Encoder import TransformerEncoder\n",
    "from Transformers.PositionalEncoding import BasicPositionalEmbeddings\n",
    "from Transformers.DataLoader import SampledTestatN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_vocab=1000, maxlen=100, embedings_dim=64, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_vocab = num_vocab\n",
    "        self.maxlen = maxlen\n",
    "        self.embedings_dim = embedings_dim\n",
    "        \n",
    "        self.emb = tf.keras.layers.Embedding(input_dim=num_vocab, output_dim=embedings_dim, mask_zero=True)\n",
    "        self.pos_emb = tfm.nlp.layers.PositionEmbedding(maxlen, initializer='glorot_uniform', seq_axis=1)\n",
    "\n",
    "    def call(self, x, **kwargs):      \n",
    "        return self.pos_emb(self.emb(x))\n",
    "        # return self.emb(x)\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        # This will return a boolean matrix where is False when found a 0 in that position\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_build_config(self):\n",
    "        return {\"num_vocab\": self.emb,\n",
    "                \"maxlen\": self.maxlen,\n",
    "                \"embedings_dim\": self.embedings_dim}\n",
    "\n",
    "\n",
    "class LandmarkEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, embedings_dim=64, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedings_dim = embedings_dim\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv1D(\n",
    "            embedings_dim, 5, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2 = tf.keras.layers.Conv1D(\n",
    "            embedings_dim, 5, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3 = tf.keras.layers.Conv1DTranspose(\n",
    "            embedings_dim, 5, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv4 = tf.keras.layers.Conv1DTranspose(\n",
    "            embedings_dim, 5, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.global_max_pooling = tf.keras.layers.GlobalMaxPooling1D()\n",
    "        self.positional_encoding = tfm.vision.layers.PositionalEncoding()\n",
    "\n",
    "    def call(self, x, **kwargs):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        # x = self.global_max_pooling(x)\n",
    "        \n",
    "        return x #self.positional_encoding(x, output_states=False)\n",
    "    \n",
    "    # def compute_mask(self, inputs, mask=None):\n",
    "    #     print(\"input: \", inputs.shape)\n",
    "    #     print(\"mask: \", mask.shape if mask is not None else \"no mask\")\n",
    "    #     # This will return a boolean matrix where is False when found a 0 in that position\n",
    "    #     print(\"mask new: \", tf.math.not_equal(inputs, 0).shape)\n",
    "\n",
    "    #     return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_build_config(self):\n",
    "        return {\"embedings_dim\": self.embedings_dim}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfm.vision.layers.PositionalEncoding()(next(iter(train_dataset_textvectorizer))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  lme = LandmarkEmbedding(embedings_dim=128)\n",
    "#  lme(next(iter(train_dataset_textvectorizer))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train_dataset_textvectorizer))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  lme = TokenEmbedding(num_vocab=VOCAB_SIZE, embedings_dim=DIM_EMBEDDINGS, maxlen=TARGET_MAX_LENGHT)\n",
    "#  lme(next(iter(train_dataset_textvectorizer))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_MAX_LENGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "DIM_EMBEDDINGS = 256\n",
    "ATTENTION_HEADS = 1\n",
    "VOCAB_SIZE = len([w for w, _ in num_to_char.items()])\n",
    "LATENT_DIMS = math.ceil(DIM_EMBEDDINGS/ATTENTION_HEADS)\n",
    "\n",
    "source_input = tf.keras.Input(shape=(None, 84), dtype=\"float32\", name=\"source\")\n",
    "target_input = tf.keras.Input(shape=(TARGET_MAX_LENGHT,), dtype=\"int64\", name=\"target\")\n",
    "\n",
    "source_emb = LandmarkEmbedding(embedings_dim=DIM_EMBEDDINGS)(source_input)\n",
    "target_emb = TokenEmbedding(embedings_dim=DIM_EMBEDDINGS, maxlen=TARGET_MAX_LENGHT+1)(target_input)\n",
    "\n",
    "encoded_sequence = TransformerEncoder(num_heads=ATTENTION_HEADS, dim_emb=DIM_EMBEDDINGS, dim_dense=LATENT_DIMS)(source_emb)\n",
    "decoded_sequence = TransformerDecoder(num_heads=ATTENTION_HEADS, dim_emb=DIM_EMBEDDINGS, dim_dense=LATENT_DIMS)(encoded_sequence, target_emb)\n",
    "decoded_sequence = tf.keras.layers.Dropout(0.5)(decoded_sequence)\n",
    "\n",
    "next_token = tf.keras.layers.Dense(units=VOCAB_SIZE, activation=\"softmax\")(decoded_sequence)\n",
    "model = tf.keras.Model(inputs=[source_input, target_input], outputs=next_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'landmark_embedding_1' (type LandmarkEmbedding).\n\nInput 0 of layer \"conv1d_2\" is incompatible with the layer: expected min_ndim=3, found ndim=1. Full shape received: (8,)\n\nCall arguments received by layer 'landmark_embedding_1' (type LandmarkEmbedding):\n  • x=tf.Tensor(shape=(8,), dtype=float32)\n  • kwargs={'training': 'None'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m source_input \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(shape\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m,))\n\u001b[0;32m----> 2\u001b[0m source_emb \u001b[39m=\u001b[39m LandmarkEmbedding(embedings_dim\u001b[39m=\u001b[39;49mDIM_EMBEDDINGS)(source_input)\n\u001b[1;32m      3\u001b[0m source_emb\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/pythonenv/fingerspelling/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[25], line 46\u001b[0m, in \u001b[0;36mLandmarkEmbedding.call\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 46\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m     47\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)\n\u001b[1;32m     48\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(x)\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'landmark_embedding_1' (type LandmarkEmbedding).\n\nInput 0 of layer \"conv1d_2\" is incompatible with the layer: expected min_ndim=3, found ndim=1. Full shape received: (8,)\n\nCall arguments received by layer 'landmark_embedding_1' (type LandmarkEmbedding):\n  • x=tf.Tensor(shape=(8,), dtype=float32)\n  • kwargs={'training': 'None'}"
     ]
    }
   ],
   "source": [
    "source_input = tf.random.uniform(shape=(8,))\n",
    "source_emb = LandmarkEmbedding(embedings_dim=DIM_EMBEDDINGS)(source_input)\n",
    "source_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_input = tf.random.uniform(shape=(8, TARGET_MAX_LENGHT,))\n",
    "target_emb = BasicPositionalEmbeddings(max_tokens=VOCAB_SIZE, dim_emb=DIM_EMBEDDINGS, max_seq_length=TARGET_MAX_LENGHT+1)(target_input)\n",
    "\n",
    "target_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_heads=self.num_heads,\n",
    "# key_dim=self.dim_emb,\n",
    "# value_dim=self.dim_dense\n",
    "\n",
    "\n",
    "mask = tf.math.not_equal(source_emb, 0)\n",
    "mask = mask[:, tf.newaxis, :]\n",
    "\n",
    "scores = tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=LATENT_DIMS, value_dim=LATENT_DIMS)(source_emb, source_emb, source_emb, attention_mask=mask)\n",
    "# scores = tf.keras.layers.MultiHeadAttention(num_heads=8, key_dim=LATENT_DIMS, value_dim=DIM_EMBEDDINGS)(source_emb, source_emb, source_emb)\n",
    "\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequence = TransformerEncoder(num_heads=8, dim_emb=DIM_EMBEDDINGS, dim_dense=LATENT_DIMS)(source_emb)\n",
    "encoded_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#input\n",
    "# source_input = tf.keras.Input(shape=(None, 84), dtype=\"float32\", name=\"source\")\n",
    "source = tf.keras.layers.Input(shape=(None, 84), dtype=\"float32\", name=\"source\")\n",
    "\n",
    "# ENCODER START\n",
    "# embeddings = LandmarkEmbedding(embedings_dim=DIM_EMBEDDINGS)(source_input)\n",
    "encoded_source = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=LATENT_DIMS), merge_mode=\"sum\")(source)\n",
    "# encoded_source = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=LATENT_DIM), merge_mode=\"sum\")(embeddings)\n",
    "# A full sentence is reduce to the last state of a LSTM\n",
    "# ENCODER END\n",
    "\n",
    "# DECODER\n",
    "# Encodded token and new generated token as inputs\n",
    "# Reverse process like the conv1DTranspose with the segmentation model\n",
    "target_input = tf.keras.Input(shape=(TARGET_MAX_LENGHT,), dtype=\"int64\", name=\"target\")\n",
    "\n",
    "#learn a representation from the target (Vocabsize, latent_dim)\n",
    "#Should this be MAX_TOKENS+1 for the END?\n",
    "latent_space = tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, output_dim=DIM_EMBEDDINGS, mask_zero=True)(target)\n",
    "\n",
    "#This will return (TARGET_SHAPE, LATENT_DIM)\n",
    "# decoder = tf.keras.layers.LSTM(units=LATENT_DIM, return_sequences=True)\n",
    "decoder = tf.keras.layers.GRU(units=LATENT_DIMS, return_sequences=True)\n",
    "\n",
    "decoded_sentence = decoder(latent_space, initial_state=encoded_source)\n",
    "\n",
    "decoded_sentence = tf.keras.layers.Dropout(0.5)(decoded_sentence)\n",
    "\n",
    "target_next_step = tf.keras.layers.Dense(units=VOCAB_SIZE, activation=\"softmax\")(decoded_sentence)\n",
    "# DECODER\n",
    "\n",
    "# CREATE MODEL ENCODER / DECODER\n",
    "encoder_decoder_model = tf.keras.Model(inputs=[source, target], outputs=target_next_step)\n",
    "\n",
    "# encoder_decoder_model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-5), metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "encoder_decoder_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_1:0\", shape=(), dtype=string)\n",
      "Tensor(\"StringsByteSplit/RaggedGetItem/strided_slice_5:0\", shape=(None,), dtype=string)\n",
      "Tensor(\"None_Lookup/LookupTableFindV2:0\", shape=(None,), dtype=int32)\n",
      "Tensor(\"add_1:0\", shape=(), dtype=string)\n",
      "Tensor(\"StringsByteSplit/RaggedGetItem/strided_slice_5:0\", shape=(None,), dtype=string)\n",
      "Tensor(\"None_Lookup/LookupTableFindV2:0\", shape=(None,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(patience=5, monitor=\"val_loss\")\n",
    "save_best_model = tf.keras.callbacks.ModelCheckpoint(filepath=\"../best_model/prototype\", save_best_only=True, save_weights_only=True)\n",
    "\n",
    "train_dataset = (tf.data.TFRecordDataset(train_files)\n",
    "                    .shuffle(32)\n",
    "                    .map(decode_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                    .map(convert_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                    .map(lambda landmark, phrase: ({\"source\":landmark, \"target\":phrase[:-1]}, phrase[1:]))\n",
    "                    .padded_batch(32)\n",
    "                    .prefetch(tf.data.AUTOTUNE)\n",
    "                )\n",
    "\n",
    "val_dataset = (tf.data.TFRecordDataset(val_files)\n",
    "                    .map(decode_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                    .map(convert_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                    .map(lambda landmark, phrase: ({\"source\":landmark, \"target\":phrase[:-1]}, phrase[1:]))\n",
    "                    .cache()\n",
    "                    .padded_batch(32)\n",
    "                    .prefetch(tf.data.AUTOTUNE)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_decoder_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " target (InputLayer)         [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " source (InputLayer)         [(None, None, 84)]           0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 256)            16128     ['target[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 256)                  525312    ['source[0][0]']              \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                 (None, None, 256)            394752    ['embedding[0][0]',           \n",
      "                                                                     'bidirectional[0][0]']       \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, None, 256)            0         ['gru_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 63)             16191     ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 952383 (3.63 MB)\n",
      "Trainable params: 952383 (3.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 16:39:22.280443: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT8\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_41/output/_22'\n",
      "2023-08-17 16:39:22.424257: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ca384c84d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-17 16:39:22.424274: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 SUPER, Compute Capability 7.5\n",
      "2023-08-17 16:39:22.444782: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-17 16:39:22.547055: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-08-17 16:39:22.592806: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-08-17 16:39:22.910571: E tensorflow/compiler/xla/stream_executor/dnn.cc:1133] CUDNN_STATUS_INTERNAL_ERROR\n",
      "in tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(2256): 'cudnnRNNBackwardData_v8( cudnn.handle(), rnn_desc.handle(), reinterpret_cast<const int*>(seq_lengths_data.opaque()), output_desc.data_handle(), output_data.opaque(), output_backprop_data.opaque(), input_desc.data_handle(), input_backprop_data->opaque(), input_h_desc.handle(), input_h_data.opaque(), output_h_backprop_data.opaque(), input_h_backprop_data->opaque(), input_c_desc.handle(), input_c_data.opaque(), output_c_backprop_data.opaque(), input_c_backprop_data->opaque(), rnn_desc.ParamsSizeInBytes(), params.opaque(), workspace.size(), workspace.opaque(), reserve_space_data->size(), reserve_space_data->opaque())'\n",
      "2023-08-17 16:39:22.910612: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at cudnn_rnn_ops.cc:2171 : INTERNAL: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 3, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 256, 256, 1, 63, 32, 0] \n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nFailed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 3, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 256, 256, 1, 63, 32, 0] \n\t [[{{node gradients/cond_grad/gradients/cond/CudnnRNNV3_grad/CudnnRNNBackpropV3_tfg_inlined_gradients/cond_grad/If_0}}]]\n\t [[PartitionedCall]] [Op:__inference_train_function_38768]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# model.fit(train_dataset, validation_data=val_dataset, epochs=1, callbacks=[early_stop, save_best_model])\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m encoder_decoder_model\u001b[39m.\u001b[39;49mfit(train_dataset, validation_data\u001b[39m=\u001b[39;49mval_dataset, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[early_stop])\n",
      "File \u001b[0;32m~/pythonenv/fingerspelling/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/pythonenv/fingerspelling/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nFailed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 3, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 256, 256, 1, 63, 32, 0] \n\t [[{{node gradients/cond_grad/gradients/cond/CudnnRNNV3_grad/CudnnRNNBackpropV3_tfg_inlined_gradients/cond_grad/If_0}}]]\n\t [[PartitionedCall]] [Op:__inference_train_function_38768]"
     ]
    }
   ],
   "source": [
    "# model.fit(train_dataset, validation_data=val_dataset, epochs=1, callbacks=[early_stop, save_best_model])\n",
    "encoder_decoder_model.fit(train_dataset, validation_data=val_dataset, epochs=1, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"../best_model/prototype\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = tf.keras.models.load_model(\"../models/v1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fingerspelling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
